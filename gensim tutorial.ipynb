{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1020ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mocka\\mambaforge\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12368/108106524.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgensim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdownloader\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mapi\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mwv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mapi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'word2vec-google-news-300'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\downloader.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(name, return_path)\u001B[0m\n\u001B[0;32m    501\u001B[0m         \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mBASE_DIR\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    502\u001B[0m         \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m__import__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 503\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    504\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    505\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~/gensim-data\\word2vec-google-news-300\\__init__.py\u001B[0m in \u001B[0;36mload_data\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'word2vec-google-news-300'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"word2vec-google-news-300.gz\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mKeyedVectors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_word2vec_format\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001B[0m in \u001B[0;36mload_word2vec_format\u001B[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001B[0m\n\u001B[0;32m   1628\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1629\u001B[0m         \"\"\"\n\u001B[1;32m-> 1630\u001B[1;33m         return _load_word2vec_format(\n\u001B[0m\u001B[0;32m   1631\u001B[0m             \u001B[0mcls\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfvocab\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfvocab\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbinary\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0municode_errors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0municode_errors\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1632\u001B[0m             \u001B[0mlimit\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlimit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdatatype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdatatype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mno_header\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mno_header\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001B[0m in \u001B[0;36m_load_word2vec_format\u001B[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001B[0m\n\u001B[0;32m   1904\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlimit\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1905\u001B[0m             \u001B[0mvocab_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlimit\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1906\u001B[1;33m         \u001B[0mkv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvector_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvocab_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdatatype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1907\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1908\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mbinary\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, vector_size, count, dtype, mapfile_path)\u001B[0m\n\u001B[0;32m    225\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkey_to_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 227\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvectors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcount\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvector_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# formerly known as syn0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    228\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08927b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6c49b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
      " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
      "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
      " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
      "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
      "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
      "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
      "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
      "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
      "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
      "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
      "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
      " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
      " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
      " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
      "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
      "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
      " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
      " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
      " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
      "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
      "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
      "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
      " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
      " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
      "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
      " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
      "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
      " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
      " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
      "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
      " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
      " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
      "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
      " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
      "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
      "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
      " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
      " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
      " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
      " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
      " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
      "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
      "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
      "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
      " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
      "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
      "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
      " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
      " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
      " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
      "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
      "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
      " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
      "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
      " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
      "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
      "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
      " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
      "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
      "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
      "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
      "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
      "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
      " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
      "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
      " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
      "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
      "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
      " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
      "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
      "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
      "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
      " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
      " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
     ]
    }
   ],
   "source": [
    "print(wv['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd238853",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '0.04296875' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5392/3742231769.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mqueen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'king'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mwv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'man'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mwv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'woman'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mqueen\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key_or_keys)\u001B[0m\n\u001B[0;32m    379\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey_or_keys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 381\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mvstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mkey_or_keys\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdefault\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    379\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey_or_keys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 381\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mvstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mkey_or_keys\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdefault\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001B[0m in \u001B[0;36mget_vector\u001B[1;34m(self, key, norm)\u001B[0m\n\u001B[0;32m    420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m         \"\"\"\n\u001B[1;32m--> 422\u001B[1;33m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    423\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mnorm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    424\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfill_norms\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001B[0m in \u001B[0;36mget_index\u001B[1;34m(self, key, default)\u001B[0m\n\u001B[0;32m    394\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mdefault\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 396\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Key '{key}' not present\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_vector\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnorm\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Key '0.04296875' not present\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6d3431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c91a8e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12368/442986742.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mwv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmost_similar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpositive\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'king'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnegative\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'men'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wv' is not defined"
     ]
    }
   ],
   "source": [
    "wv.most_similar(positive=['king'], negative=['men'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d4b442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('goalie_Jacob_Markstrom', 0.32512784004211426),\n",
       " ('maroon', 0.31353095173835754),\n",
       " ('blue_windbreaker', 0.3075973093509674),\n",
       " ('emblazoned', 0.30597206950187683),\n",
       " ('flicked_backhander', 0.2959442734718323),\n",
       " ('sweat_shirt', 0.2959163784980774),\n",
       " ('goalie_Robin_Lehner', 0.29398655891418457),\n",
       " ('Denis_Reul', 0.2928417921066284),\n",
       " ('navy_blue', 0.2919740080833435),\n",
       " ('Philippe_Furrer', 0.2896328270435333)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['blue'], negative=['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9439264f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tome', 0.4451513886451721),\n",
       " ('paperback_edition', 0.43923020362854004),\n",
       " ('paperback', 0.4296383559703827),\n",
       " ('bestseller', 0.4282079041004181),\n",
       " ('softcover', 0.41957396268844604),\n",
       " ('memoir', 0.415959894657135),\n",
       " ('novel', 0.41153484582901),\n",
       " ('books', 0.40470150113105774),\n",
       " ('Complete_Peanuts', 0.403852641582489),\n",
       " ('bestselling_book', 0.401568204164505)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['book'], negative=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c47ed354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('memoir', 0.5550488233566284),\n",
       " ('autobiography', 0.5206078290939331),\n",
       " ('paperback_edition', 0.5201478600502014),\n",
       " ('tome', 0.5027788281440735),\n",
       " ('books', 0.47897571325302124),\n",
       " ('memoirs', 0.47314611077308655),\n",
       " ('biography', 0.46764808893203735),\n",
       " ('bestselling_book', 0.4516701400279999),\n",
       " ('cookbook', 0.426254540681839),\n",
       " ('Book', 0.42063701152801514)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['book'], negative=['binding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca57c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blue_jeans', 0.3820299804210663),\n",
       " ('pants', 0.3371451199054718),\n",
       " ('briefcase', 0.33651742339134216),\n",
       " ('unshaven', 0.33560606837272644),\n",
       " ('tennis_shoes', 0.3315977156162262),\n",
       " ('underpants', 0.33003970980644226),\n",
       " ('faded_jeans', 0.32288962602615356),\n",
       " ('clean_shaven', 0.32109126448631287),\n",
       " ('leather_jacket', 0.3195229470729828),\n",
       " ('pocket', 0.3184541165828705)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['jeans'], negative=['denim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f04573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('algebra', 0.5956398844718933),\n",
       " ('mathematics', 0.5492819547653198),\n",
       " ('Math', 0.545730710029602),\n",
       " ('Algebra_II', 0.49358272552490234),\n",
       " ('trigonometry', 0.4782160520553589),\n",
       " ('WASL', 0.4648856222629547),\n",
       " ('standardized_tests', 0.46280568838119507),\n",
       " ('Algebra', 0.4585016965866089),\n",
       " ('reading_comprehension', 0.45819324254989624),\n",
       " ('Language_Arts', 0.4566376209259033)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['math'], negative=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7992c8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hefty_tome', 0.31779420375823975),\n",
       " ('glossy_paged', 0.316241592168808),\n",
       " ('dog_eared_copies', 0.31448590755462646),\n",
       " ('mags', 0.3114660084247589),\n",
       " ('guidebook', 0.31127434968948364),\n",
       " ('mag', 0.2996074855327606),\n",
       " ('PAGES', 0.2936566472053528),\n",
       " ('tome', 0.29344525933265686),\n",
       " ('Handbook', 0.28914639353752136),\n",
       " ('guide', 0.28867045044898987)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['bible'], negative=['religion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6979b486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('israeli', 0.411335825920105),\n",
       " ('colo', 0.34614357352256775),\n",
       " ('dutch', 0.34030529856681824),\n",
       " ('sherman', 0.33464792370796204),\n",
       " ('miguel', 0.32965999841690063),\n",
       " ('tish', 0.32717111706733704),\n",
       " ('thomas', 0.3260112404823303),\n",
       " ('norway', 0.3249763548374176),\n",
       " ('america', 0.3211340308189392),\n",
       " ('los_angeles', 0.32010507583618164)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['jewish'], negative=['religion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17737b1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bibles', 0.32099923491477966),\n",
       " ('Practical_Parenting', 0.3101576864719391),\n",
       " ('ATA_Martial_Arts', 0.30729708075523376),\n",
       " ('Baptist_Healthplex', 0.30591753125190735),\n",
       " ('Boy_Scout_Merit_Badge', 0.30569562315940857),\n",
       " ('Harold_Camping_speaks', 0.2966490387916565),\n",
       " ('Professional_Bartending', 0.2936627268791199),\n",
       " ('Christianity_Explored', 0.2926352620124817),\n",
       " ('Trap_Shooting', 0.29201558232307434),\n",
       " ('Homeschoolers', 0.2909623384475708)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "821f5e38",
   "metadata": {},
   "source": [
    "# Training your own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b23674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe80093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c17ffc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1704efa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " [{'section': 'capital-common-countries',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN')]},\n",
       "  {'section': 'capital-world',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE')]},\n",
       "  {'section': 'currency', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'city-in-state', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'family',\n",
       "   'correct': [],\n",
       "   'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER')]},\n",
       "  {'section': 'gram1-adjective-to-adverb', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram2-opposite', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram3-comparative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER')]},\n",
       "  {'section': 'gram4-superlative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')]},\n",
       "  {'section': 'gram5-present-participle',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING')]},\n",
       "  {'section': 'gram6-nationality-adjective',\n",
       "   'correct': [],\n",
       "   'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE')]},\n",
       "  {'section': 'gram7-past-tense',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID')]},\n",
       "  {'section': 'gram8-plural',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]},\n",
       "  {'section': 'gram9-plural-verbs', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'Total accuracy',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER'),\n",
       "    ('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER'),\n",
       "    ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n",
       "    ('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE'),\n",
       "    ('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa4e9d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5392/3267010020.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[0mplot_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplot_with_plotly\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 62\u001B[1;33m \u001B[0mplot_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_vals\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_vals\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5392/3267010020.py\u001B[0m in \u001B[0;36mplot_with_plotly\u001B[1;34m(x_vals, y_vals, labels, plot_in_notebook)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mplot_with_plotly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_vals\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_vals\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot_in_notebook\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m     \u001B[1;32mfrom\u001B[0m \u001B[0mplotly\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moffline\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minit_notebook_mode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miplot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m     \u001B[1;32mimport\u001B[0m \u001B[0mplotly\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgraph_objs\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mgo\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    # extract the words & their vectors, as numpy arrays\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}