{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1020ffa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to read local cache '/Users/gabrielaspir/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gabrielaspir/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5428eb1c8be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec-google-news-300'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \"\"\"\n\u001b[1;32m    489\u001b[0m     \u001b[0m_create_base_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect model/corpus name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_get_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0minformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0mcorpora\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'corpora'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36minfo\u001b[0;34m(name, show_only_latest, name_only)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0minformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_load_info\u001b[0;34m(url, encoding)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;34m'unable to read local cache %r during fallback, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m'connect to the Internet and retry'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unable to read local cache '/Users/gabrielaspir/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08927b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-06f7e7d29126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"word #{index}/{len(wv.index_to_key)} is {word}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wv' is not defined"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6c49b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1c69db575d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'king'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wv' is not defined"
     ]
    }
   ],
   "source": [
    "print(wv['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd238853",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '0.04296875' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5392/3742231769.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mqueen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'king'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'man'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'woman'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqueen\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \"\"\"\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\mambaforge\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key '0.04296875' not present\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6d3431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c91a8e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12368/442986742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'king'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'men'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wv' is not defined"
     ]
    }
   ],
   "source": [
    "wv.most_similar(positive=['king'], negative=['men'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d4b442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('goalie_Jacob_Markstrom', 0.32512784004211426),\n",
       " ('maroon', 0.31353095173835754),\n",
       " ('blue_windbreaker', 0.3075973093509674),\n",
       " ('emblazoned', 0.30597206950187683),\n",
       " ('flicked_backhander', 0.2959442734718323),\n",
       " ('sweat_shirt', 0.2959163784980774),\n",
       " ('goalie_Robin_Lehner', 0.29398655891418457),\n",
       " ('Denis_Reul', 0.2928417921066284),\n",
       " ('navy_blue', 0.2919740080833435),\n",
       " ('Philippe_Furrer', 0.2896328270435333)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['blue'], negative=['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9439264f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tome', 0.4451513886451721),\n",
       " ('paperback_edition', 0.43923020362854004),\n",
       " ('paperback', 0.4296383559703827),\n",
       " ('bestseller', 0.4282079041004181),\n",
       " ('softcover', 0.41957396268844604),\n",
       " ('memoir', 0.415959894657135),\n",
       " ('novel', 0.41153484582901),\n",
       " ('books', 0.40470150113105774),\n",
       " ('Complete_Peanuts', 0.403852641582489),\n",
       " ('bestselling_book', 0.401568204164505)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['book'], negative=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c47ed354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('memoir', 0.5550488233566284),\n",
       " ('autobiography', 0.5206078290939331),\n",
       " ('paperback_edition', 0.5201478600502014),\n",
       " ('tome', 0.5027788281440735),\n",
       " ('books', 0.47897571325302124),\n",
       " ('memoirs', 0.47314611077308655),\n",
       " ('biography', 0.46764808893203735),\n",
       " ('bestselling_book', 0.4516701400279999),\n",
       " ('cookbook', 0.426254540681839),\n",
       " ('Book', 0.42063701152801514)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['book'], negative=['binding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca57c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blue_jeans', 0.3820299804210663),\n",
       " ('pants', 0.3371451199054718),\n",
       " ('briefcase', 0.33651742339134216),\n",
       " ('unshaven', 0.33560606837272644),\n",
       " ('tennis_shoes', 0.3315977156162262),\n",
       " ('underpants', 0.33003970980644226),\n",
       " ('faded_jeans', 0.32288962602615356),\n",
       " ('clean_shaven', 0.32109126448631287),\n",
       " ('leather_jacket', 0.3195229470729828),\n",
       " ('pocket', 0.3184541165828705)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['jeans'], negative=['denim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f04573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('algebra', 0.5956398844718933),\n",
       " ('mathematics', 0.5492819547653198),\n",
       " ('Math', 0.545730710029602),\n",
       " ('Algebra_II', 0.49358272552490234),\n",
       " ('trigonometry', 0.4782160520553589),\n",
       " ('WASL', 0.4648856222629547),\n",
       " ('standardized_tests', 0.46280568838119507),\n",
       " ('Algebra', 0.4585016965866089),\n",
       " ('reading_comprehension', 0.45819324254989624),\n",
       " ('Language_Arts', 0.4566376209259033)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['math'], negative=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7992c8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hefty_tome', 0.31779420375823975),\n",
       " ('glossy_paged', 0.316241592168808),\n",
       " ('dog_eared_copies', 0.31448590755462646),\n",
       " ('mags', 0.3114660084247589),\n",
       " ('guidebook', 0.31127434968948364),\n",
       " ('mag', 0.2996074855327606),\n",
       " ('PAGES', 0.2936566472053528),\n",
       " ('tome', 0.29344525933265686),\n",
       " ('Handbook', 0.28914639353752136),\n",
       " ('guide', 0.28867045044898987)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['bible'], negative=['religion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6979b486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('israeli', 0.411335825920105),\n",
       " ('colo', 0.34614357352256775),\n",
       " ('dutch', 0.34030529856681824),\n",
       " ('sherman', 0.33464792370796204),\n",
       " ('miguel', 0.32965999841690063),\n",
       " ('tish', 0.32717111706733704),\n",
       " ('thomas', 0.3260112404823303),\n",
       " ('norway', 0.3249763548374176),\n",
       " ('america', 0.3211340308189392),\n",
       " ('los_angeles', 0.32010507583618164)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['jewish'], negative=['religion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17737b1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bibles', 0.32099923491477966),\n",
       " ('Practical_Parenting', 0.3101576864719391),\n",
       " ('ATA_Martial_Arts', 0.30729708075523376),\n",
       " ('Baptist_Healthplex', 0.30591753125190735),\n",
       " ('Boy_Scout_Merit_Badge', 0.30569562315940857),\n",
       " ('Harold_Camping_speaks', 0.2966490387916565),\n",
       " ('Professional_Bartending', 0.2936627268791199),\n",
       " ('Christianity_Explored', 0.2926352620124817),\n",
       " ('Trap_Shooting', 0.29201558232307434),\n",
       " ('Homeschoolers', 0.2909623384475708)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "821f5e38",
   "metadata": {},
   "source": [
    "# Training your own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b23674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe80093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c17ffc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1704efa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " [{'section': 'capital-common-countries',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN')]},\n",
       "  {'section': 'capital-world',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE')]},\n",
       "  {'section': 'currency', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'city-in-state', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'family',\n",
       "   'correct': [],\n",
       "   'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER')]},\n",
       "  {'section': 'gram1-adjective-to-adverb', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram2-opposite', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'gram3-comparative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER')]},\n",
       "  {'section': 'gram4-superlative',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')]},\n",
       "  {'section': 'gram5-present-participle',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING')]},\n",
       "  {'section': 'gram6-nationality-adjective',\n",
       "   'correct': [],\n",
       "   'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE')]},\n",
       "  {'section': 'gram7-past-tense',\n",
       "   'correct': [],\n",
       "   'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID')]},\n",
       "  {'section': 'gram8-plural',\n",
       "   'correct': [],\n",
       "   'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]},\n",
       "  {'section': 'gram9-plural-verbs', 'correct': [], 'incorrect': []},\n",
       "  {'section': 'Total accuracy',\n",
       "   'correct': [],\n",
       "   'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "    ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "    ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "    ('HE', 'SHE', 'HIS', 'HER'),\n",
       "    ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "    ('HIS', 'HER', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "    ('MAN', 'WOMAN', 'HIS', 'HER'),\n",
       "    ('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "    ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "    ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "    ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "    ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "    ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "    ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "    ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "    ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "    ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "    ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "    ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "    ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "    ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "    ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "    ('SMALL', 'SMALLER', 'LOW', 'LOWER'),\n",
       "    ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "    ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "    ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "    ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "    ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "    ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "    ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "    ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "    ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n",
       "    ('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "    ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "    ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "    ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "    ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "    ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "    ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "    ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "    ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "    ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "    ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "    ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "    ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "    ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "    ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "    ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "    ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "    ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "    ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "    ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "    ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "    ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "    ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "    ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "    ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "    ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "    ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "    ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "    ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "    ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "    ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "    ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE'),\n",
       "    ('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "    ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "    ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "    ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "    ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "    ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "    ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "    ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "    ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "    ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "    ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "    ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "    ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "    ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "    ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "    ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "    ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "    ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "    ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "    ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "    ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "    ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "    ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "    ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "    ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "    ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "    ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "    ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "    ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "    ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "    ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "    ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "    ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "    ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "    ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "    ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa4e9d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5392/3267010020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mplot_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_with_plotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mplot_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5392/3267010020.py\u001b[0m in \u001b[0;36mplot_with_plotly\u001b[1;34m(x_vals, y_vals, labels, plot_in_notebook)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_with_plotly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_in_notebook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    # extract the words & their vectors, as numpy arrays\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
